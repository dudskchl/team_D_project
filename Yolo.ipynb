{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1iWFXidGvsTvkqsLsVf1uEYe1i9IVZo5J",
      "authorship_tag": "ABX9TyOTZ5541YpzMKdyjIJKZqIK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dudskchl/team_D_project/blob/main/Yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!pip install supervision\n",
        "!pip install flask-ngrok\n",
        "!pip install colab-ssh\n",
        "!pip install flask\n",
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "BTMYdjne6Yyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.set_auth_token('')"
      ],
      "metadata": {
        "id": "QRTPD8NRXI_Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile app.py\n",
        "\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "from ultralytics import YOLO\n",
        "from flask import Flask, url_for, redirect, render_template, request, Response\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from colab_ssh import launch_ssh\n",
        "from pyngrok import ngrok\n",
        "import requests\n",
        "import os\n",
        "import argparse\n",
        "import supervision as sv\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import streamlit as st\n",
        "\n",
        "TEMPLATE_FOLDER = '/content/drive/MyDrive/ver_local/templates'\n",
        "STATIC_FOLDER = '/content/drive/MyDrive/ver_local/statics'\n",
        "\n",
        "app = Flask(__name__, template_folder=TEMPLATE_FOLDER, static_folder = STATIC_FOLDER)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "# array -> image -> string\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes\n",
        "\n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data\n",
        "\n",
        "# use 0 for local web camera/ camera = cv2.VideoCapture(0)  \n",
        "\n",
        "\n",
        "def parse_arguments() -> argparse.Namespace:\n",
        "    parser = argparse.ArgumentParser(description=\"YOLOv8 live\")\n",
        "    parser.add_argument(\n",
        "        \"--webcam-resolution\", \n",
        "        default=[640, 480], \n",
        "        nargs=2, \n",
        "        type=int\n",
        "    )\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "def gen_frames():  # generate frame by frame from camera\n",
        "    args = parse_arguments()\n",
        "    frame_width, frame_height = args.webcam_resolution\n",
        "\n",
        "    model = YOLO(\"/content/drive/MyDrive/ver_local/best.pt\")\n",
        "    box_annotator = sv.BoxAnnotator(thickness=2, text_thickness=2, text_scale=1)\n",
        "\n",
        "    # start streaming video from webcam\n",
        "    video_stream()\n",
        "    label_html = 'Capturing...'\n",
        "    bbox = ''\n",
        "    count = 0 \n",
        "    while True:\n",
        "        # Capture frame-by-frame\n",
        "        js_reply = video_frame(label_html, bbox)\n",
        "        if not js_reply:\n",
        "            break\n",
        "        else:\n",
        "            # convert JS response to OpenCV Image\n",
        "            img = js_to_image(js_reply[\"img\"])\n",
        "            # create transparent overlay for bounding box\n",
        "            bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "            \n",
        "            result = model(frame, agnostic_nms=True)[0]\n",
        "            detections = sv.Detections.from_yolov8(result)\n",
        "            print(detections)\n",
        "            \n",
        "            labels = [f\"{model.model.names[class_id]} {confidence:0.2f}\" for _, _, confidence, class_id, _ in detections]\n",
        "            print(labels)\n",
        "            frame = box_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
        "            ret, buffer = cv2.imencode('.jpg', frame)\n",
        "            frame = buffer.tobytes()\n",
        "\n",
        "            yield (b'--frame\\r\\n'\n",
        "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')  # concat frame one by one and show result\n",
        "\n",
        "\n",
        "@app.route('/video_feed')\n",
        "def video_feed():\n",
        "    #Video streaming route. Put this in the src attribute of an img tag\n",
        "    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    \"\"\"Video streaming home page.\"\"\"\n",
        "    return render_template('index.html')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "id": "f6_25mgwO8uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py --server.port %%&"
      ],
      "metadata": {
        "id": "5fdl8di83pZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0eae9e-c41f-49d1-b59c-9bc046cac076"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = ngrok.connect(port='')\n",
        "url"
      ],
      "metadata": {
        "id": "QtLJPJjW32T5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}